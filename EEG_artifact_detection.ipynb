{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D  # noqa\n",
    "import mne\n",
    "import numpy as np\n",
    "import mne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyeeglab import    TUHEEGArtifactDataset, SinglePickleCache, Pipeline, CommonChannelSet, \\\n",
    "                        LowestFrequency, ToDataframe, DynamicWindow, BinarizedSpearmanCorrelation, \\\n",
    "                        ToNumpy, JoinedPreprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyeeglab import  BandPassFrequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "try:\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "except RuntimeError as e:\n",
    "    print(e)\n",
    "\n",
    "from tensorflow.keras import Model, Input\n",
    "from tensorflow.keras.layers import Dense, Concatenate, Reshape, Flatten, LSTM\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from spektral.layers import GraphAttention\n",
    "from spektral.utils import nx_to_adj, nx_to_node_features, add_eye\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from tensorflow.keras import Model, Input\n",
    "from tensorflow.keras.layers import Dense, Concatenate, Reshape, Flatten, Conv2D, MaxPool2D, LSTM\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "from pyeeglab import CorrelationToAdjacency, Bandpower, GraphWithFeatures, Kurtosis, AbsoluteArea, ZeroCrossing, StaticWindowOverlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "def f1_metric(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TUHEEGArtifactDataset('./data/tuh_eeg_artifact/v1.0.0/edf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.set_cache_manager(SinglePickleCache('./export'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preprocessing = Pipeline([\n",
    "    CommonChannelSet(),\n",
    "    LowestFrequency(),\n",
    "    BandPassFrequency(0.1, 47),\n",
    "    ToDataframe(),\n",
    "    DynamicWindow(16),\n",
    "    BinarizedSpearmanCorrelation(),\n",
    "    ToNumpy()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TUHEEGArtifactDataset('./data/tuh_eeg_artifact/v1.0.0/edf')\n",
    "dataset.set_cache_manager(SinglePickleCache('./export'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.set_pipeline(preprocessing).set_minimum_event_duration(3).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, labels = dataset['data'], dataset['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels[labels != 4] = 1\n",
    "labels[labels == 4] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjs = np.array(data[0]).shape[0]\n",
    "classes = len(set(labels))\n",
    "input_shape = np.array(data[0]).shape[1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [[] for _ in range(adjs)]\n",
    "for d in data:\n",
    "    for i in range(adjs):\n",
    "        inputs[i].append(d[i].reshape((*input_shape, 1)))\n",
    "data = [np.array(i) for i in inputs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_acc = 0\n",
    "total_f1 = 0\n",
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_idx, test_idx in skf.split(data[0], labels):\n",
    "    x_train, y_train = [d[train_idx] for d in data], labels[train_idx]\n",
    "    x_test, y_test = [d[test_idx] for d in data], labels[test_idx]\n",
    "\n",
    "    y_train_cat = to_categorical(y_train)\n",
    "    y_test_cat = to_categorical(y_test)\n",
    "\n",
    "    cnns = []\n",
    "    for _ in range(adjs):\n",
    "        input_a = Input((*input_shape, 1))\n",
    "        x = Conv2D(8, 3)(input_a)\n",
    "        x = MaxPool2D(2)(x)\n",
    "        x = Flatten()(x)\n",
    "        x = Model(inputs=[input_a], outputs=x)\n",
    "        cnns.append(x)\n",
    "\n",
    "    combine = Concatenate()([x.output for x in cnns])\n",
    "    reshape = Reshape((len(cnns), cnns[0].output_shape[1]))(combine)\n",
    "    lstm = LSTM(32)(reshape)\n",
    "    z = Dense(classes, activation='softmax')(lstm)\n",
    "\n",
    "    model = Model(inputs=[x.input for x in cnns], outputs=z)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy', f1_metric])\n",
    "    model.fit(x_train, y_train_cat, batch_size=32, epochs=50, shuffle=True, validation_split=0.1)\n",
    "    y_pred = model.predict(x_test).argmax(axis=-1)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    print(\"Fold accuracy: {:2.2f}\".format(acc))\n",
    "    matrix = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Fold confusion matrix: \\n {}\".format(matrix))\n",
    "    total_acc += acc/n_splits\n",
    "    total_f1 += f1/n_splits\n",
    "\n",
    "print(\"Total model accuracy: {:2.2f}\".format(total_acc))\n",
    "print(\"Total model f1: {:2.2f}\".format(total_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing = Pipeline([\n",
    "    CommonChannelSet(),\n",
    "    LowestFrequency(),\n",
    "    ToDataframe(),\n",
    "    DynamicWindow(4),\n",
    "    BinarizedSpearmanCorrelation(),\n",
    "    ToNumpy()\n",
    "])\n",
    "dataset = TUHEEGArtifactDataset('./data/tuh_eeg_artifact/v1.0.0/edf')\n",
    "dataset.set_cache_manager(SinglePickleCache('./export'))\n",
    "dataset = dataset.set_pipeline(preprocessing).set_minimum_event_duration(6).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, labels = dataset['data'], dataset['labels']\n",
    "labels[labels != 4] = 1\n",
    "labels[labels == 4] = 0\n",
    "adjs = np.array(data[0]).shape[0]\n",
    "classes = len(set(labels))\n",
    "input_shape = np.array(data[0]).shape[1:]\n",
    "inputs = [[] for _ in range(adjs)]\n",
    "for d in data:\n",
    "    for i in range(adjs):\n",
    "        inputs[i].append(d[i].reshape((*input_shape, 1)))\n",
    "data = [np.array(i) for i in inputs]\n",
    "total_acc = 0\n",
    "total_f1 = 0\n",
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_idx, test_idx in skf.split(data[0], labels):\n",
    "    x_train, y_train = [d[train_idx] for d in data], labels[train_idx]\n",
    "    x_test, y_test = [d[test_idx] for d in data], labels[test_idx]\n",
    "\n",
    "    y_train_cat = to_categorical(y_train)\n",
    "    y_test_cat = to_categorical(y_test)\n",
    "\n",
    "    cnns = []\n",
    "    for _ in range(adjs):\n",
    "        input_a = Input((*input_shape, 1))\n",
    "        x = Conv2D(8, 3)(input_a)\n",
    "        x = MaxPool2D(2)(x)\n",
    "        x = Flatten()(x)\n",
    "        x = Model(inputs=[input_a], outputs=x)\n",
    "        cnns.append(x)\n",
    "\n",
    "    combine = Concatenate()([x.output for x in cnns])\n",
    "    reshape = Reshape((len(cnns), cnns[0].output_shape[1]))(combine)\n",
    "    lstm = LSTM(32)(reshape)\n",
    "    z = Dense(classes, activation='softmax')(lstm)\n",
    "\n",
    "    model = Model(inputs=[x.input for x in cnns], outputs=z)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy', f1_metric])\n",
    "    model.fit(x_train, y_train_cat, batch_size=32, epochs=50, shuffle=True, validation_split=0.1)\n",
    "    y_pred = model.predict(x_test).argmax(axis=-1)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    print(\"Fold accuracy: {:2.2f}\".format(acc))\n",
    "    matrix = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Fold confusion matrix: \\n {}\".format(matrix))\n",
    "    total_acc += acc/n_splits\n",
    "    total_f1 += f1/n_splits\n",
    "\n",
    "print(\"Total model accuracy: {:2.2f}\".format(total_acc))\n",
    "print(\"Total model f1: {:2.2f}\".format(total_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing = Pipeline([\n",
    "    CommonChannelSet(['EEG T1-REF', 'EEG T2-REF']),\n",
    "    LowestFrequency(),\n",
    "    BandPassFrequency(0.1, 47),\n",
    "    ToDataframe(),\n",
    "    DynamicWindow(8),\n",
    "    BinarizedSpearmanCorrelation(),\n",
    "    ToNumpy()\n",
    "])\n",
    "dataset = TUHEEGArtifactDataset('./data/tuh_eeg_artifact/v1.0.0/edf')\n",
    "dataset.set_cache_manager(SinglePickleCache('./export'))\n",
    "dataset = dataset.set_pipeline(preprocessing).set_minimum_event_duration(3).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, labels = dataset['data'], dataset['labels']\n",
    "adjs = np.array(data[0]).shape[0]\n",
    "classes = len(set(labels))\n",
    "input_shape = np.array(data[0]).shape[1:]\n",
    "inputs = [[] for _ in range(adjs)]\n",
    "for d in data:\n",
    "    for i in range(adjs):\n",
    "        inputs[i].append(d[i].reshape((*input_shape, 1)))\n",
    "data = [np.array(i) for i in inputs]\n",
    "total_acc = 0\n",
    "total_f1 = 0\n",
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_acc = 0\n",
    "total_f1 = 0\n",
    "n_splits = 2\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True)\n",
    "i = 0\n",
    "for train_idx, test_idx in skf.split(data[0], labels):\n",
    "    i+=1\n",
    "    x_train, y_train = [d[train_idx] for d in data], labels[train_idx]\n",
    "    x_test, y_test = [d[test_idx] for d in data], labels[test_idx]\n",
    "\n",
    "    y_train_cat = to_categorical(y_train)\n",
    "    y_test_cat = to_categorical(y_test)\n",
    "\n",
    "    cnns = []\n",
    "    for _ in range(adjs):\n",
    "        input_a = Input((*input_shape, 1))\n",
    "        x = Conv2D(8, 3)(input_a)\n",
    "        x = MaxPool2D(2)(x)\n",
    "        x = Flatten()(x)\n",
    "        x = Model(inputs=[input_a], outputs=x)\n",
    "        cnns.append(x)\n",
    "\n",
    "    combine = Concatenate()([x.output for x in cnns])\n",
    "    reshape = Reshape((len(cnns), cnns[0].output_shape[1]))(combine)\n",
    "    lstm = LSTM(32)(reshape)\n",
    "    z = Dense(classes, activation='softmax')(lstm)\n",
    "    \n",
    "    model = Model(inputs=[x.input for x in cnns], outputs=z)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy', f1_metric])\n",
    "    model.fit(x_train, y_train_cat, batch_size=32, epochs=25, shuffle=True, validation_split=0.25)\n",
    "    y_pred = model.predict(x_test).argmax(axis=-1)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    print(\"Fold accuracy: {:2.2f}\".format(acc))\n",
    "    print(\"Fold f1: {:2.2f}\".format(f1))\n",
    "    matrix = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Fold confusion matrix: \\n {}\".format(matrix))\n",
    "    total_acc += acc/n_splits\n",
    "    total_f1 += f1/n_splits\n",
    "\n",
    "print(\"Total model accuracy: {:2.2f}\".format(total_acc))\n",
    "print(\"Total model f1: {:2.2f}\".format(total_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing = Pipeline([\n",
    "    CommonChannelSet(['EEG T1-REF', 'EEG T2-REF']),\n",
    "    LowestFrequency(),\n",
    "    BandPassFrequency(0.1, 47),\n",
    "    ToDataframe(),\n",
    "    DynamicWindow(8),\n",
    "    BinarizedSpearmanCorrelation(),\n",
    "    ToNumpy()\n",
    "])\n",
    "dataset = TUHEEGArtifactDataset('./data/tuh_eeg_artifact/v1.0.0/edf')\n",
    "dataset.set_cache_manager(SinglePickleCache('./export'))\n",
    "dataset = dataset.set_pipeline(preprocessing).set_minimum_event_duration(6).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, labels = dataset['data'], dataset['labels']\n",
    "adjs = np.array(data[0]).shape[0]\n",
    "classes = len(set(labels))\n",
    "input_shape = np.array(data[0]).shape[1:]\n",
    "inputs = [[] for _ in range(adjs)]\n",
    "for d in data:\n",
    "    for i in range(adjs):\n",
    "        inputs[i].append(d[i].reshape((*input_shape, 1)))\n",
    "data = [np.array(i) for i in inputs]\n",
    "total_acc = 0\n",
    "total_f1 = 0\n",
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "total_acc = 0\n",
    "total_f1 = 0\n",
    "n_splits = 2\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True)\n",
    "i = 0\n",
    "for train_idx, test_idx in skf.split(data[0], labels):\n",
    "    i+=1\n",
    "    x_train, y_train = [d[train_idx] for d in data], labels[train_idx]\n",
    "    x_test, y_test = [d[test_idx] for d in data], labels[test_idx]\n",
    "\n",
    "    y_train_cat = to_categorical(y_train)\n",
    "    y_test_cat = to_categorical(y_test)\n",
    "\n",
    "    cnns = []\n",
    "    for _ in range(adjs):\n",
    "        input_a = Input((*input_shape, 1))\n",
    "        x = Conv2D(8, 3)(input_a)\n",
    "        x = MaxPool2D(2)(x)\n",
    "        x = Flatten()(x)\n",
    "        x = Model(inputs=[input_a], outputs=x)\n",
    "        cnns.append(x)\n",
    "\n",
    "    combine = Concatenate()([x.output for x in cnns])\n",
    "    reshape = Reshape((len(cnns), cnns[0].output_shape[1]))(combine)\n",
    "    lstm = LSTM(32)(reshape)\n",
    "    z = Dense(classes, activation='softmax')(lstm)\n",
    "    \n",
    "    model = Model(inputs=[x.input for x in cnns], outputs=z)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy', f1_metric])\n",
    "    model.fit(x_train, y_train_cat, batch_size=32, epochs=25, shuffle=True, validation_split=0.1)\n",
    "    y_pred = model.predict(x_test).argmax(axis=-1)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    print(\"Fold accuracy: {:2.2f}\".format(acc))\n",
    "    print(\"Fold f1: {:2.2f}\".format(f1))\n",
    "    matrix = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Fold confusion matrix: \\n {}\".format(matrix))\n",
    "    total_acc += acc/n_splits\n",
    "    total_f1 += f1/n_splits\n",
    "\n",
    "print(\"Total model accuracy: {:2.2f}\".format(total_acc))\n",
    "print(\"Total model f1: {:2.2f}\".format(total_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_acc = 0\n",
    "total_f1 = 0\n",
    "n_splits = 2\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True)\n",
    "i = 0\n",
    "for train_idx, test_idx in skf.split(data[0], labels):\n",
    "    i+=1\n",
    "    x_train, y_train = [d[train_idx] for d in data], labels[train_idx]\n",
    "    x_test, y_test = [d[test_idx] for d in data], labels[test_idx]\n",
    "\n",
    "    y_train_cat = to_categorical(y_train)\n",
    "    y_test_cat = to_categorical(y_test)\n",
    "\n",
    "    cnns = []\n",
    "    for _ in range(adjs):\n",
    "        input_a = Input((*input_shape, 1))\n",
    "        x = Conv2D(8, 3)(input_a)\n",
    "        x = MaxPool2D(2)(x)\n",
    "        x = Flatten()(x)\n",
    "        x = Model(inputs=[input_a], outputs=x)\n",
    "        cnns.append(x)\n",
    "\n",
    "    combine = Concatenate()([x.output for x in cnns])\n",
    "    z = Dense(classes, activation='softmax')(combine)\n",
    "    \n",
    "    model = Model(inputs=[x.input for x in cnns], outputs=z)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy', f1_metric])\n",
    "    model.fit(x_train, y_train_cat, batch_size=32, epochs=25, shuffle=True, validation_split=0.1)\n",
    "    y_pred = model.predict(x_test).argmax(axis=-1)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    print(\"Fold accuracy: {:2.2f}\".format(acc))\n",
    "    print(\"Fold f1: {:2.2f}\".format(f1))\n",
    "    matrix = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Fold confusion matrix: \\n {}\".format(matrix))\n",
    "    total_acc += acc/n_splits\n",
    "    total_f1 += f1/n_splits\n",
    "\n",
    "print(\"Total model accuracy: {:2.2f}\".format(total_acc))\n",
    "print(\"Total model f1: {:2.2f}\".format(total_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loss = model.history.history['loss']\n",
    "test_loss = model.history.history['val_loss']\n",
    "\n",
    "# Create count of the number of epochs\n",
    "epoch_count = range(1, len(training_loss) + 1)\n",
    "\n",
    "# Visualize loss history\n",
    "plt.plot(epoch_count, training_loss, 'r--')\n",
    "plt.plot(epoch_count, test_loss, 'b-')\n",
    "plt.legend(['Training Loss', 'Test Loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(matrix, columns=dataset['labels_encoder']).to_csv('results2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydot\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_img_file = 'model_1.png'\n",
    "plot_model(model, to_file=dot_img_file, show_layer_names=False, show_shapes=True,rankdir='LR')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, labels = dataset['data'], dataset['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_reformated = data.reshape((data.shape[0], data.shape[1] * data.shape[2] * data.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_reformated.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data_reformated, labels, test_size=0.2, random_state=123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_train = xgb.DMatrix(X_train, label=y_train)\n",
    "D_test = xgb.DMatrix(X_test, label=y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    'eta': 0.3, \n",
    "    'max_depth': 4,  \n",
    "    'objective': 'multi:softprob',  \n",
    "    'num_class': len(set(labels))} \n",
    "\n",
    "steps = 100  # The number of training iterations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.train(param, D_train, steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
    "\n",
    "preds = model.predict(D_test)\n",
    "best_preds = np.asarray([np.argmax(line) for line in preds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CatBoostClassifier(iterations=50,\n",
    "                           learning_rate=1,\n",
    "                           loss_function='MultiClass',\n",
    "                           verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"f1 = {}\".format(f1_score(y_test, best_preds, average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"f1 = {}\".format(accuracy_score(y_test, best_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_acc = 0\n",
    "total_f1 = 0\n",
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True)\n",
    "i = 0\n",
    "for train_idx, test_idx in skf.split(data_reformated, labels):\n",
    "    i+=1\n",
    "    X_train, X_test = data_reformated[train_idx], data_reformated[test_idx]\n",
    "    y_train, y_test = labels[train_idx], labels[test_idx]\n",
    "    model = CatBoostClassifier(iterations=50,\n",
    "                           learning_rate=1,\n",
    "                           loss_function='MultiClass')\n",
    "    model.fit(X_train, y_train, verbose=False)\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    print(\"Fold accuracy: {:2.2f}\".format(acc))\n",
    "    print(\"Fold f1: {:2.2f}\".format(f1))\n",
    "    matrix = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Fold confusion matrix: \\n {}\".format(matrix))\n",
    "    total_acc += acc/n_splits\n",
    "    total_f1 += f1/n_splits\n",
    "\n",
    "print(\"Total model accuracy: {:2.2f}\".format(total_acc))\n",
    "print(\"Total model f1: {:2.2f}\".format(total_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_acc = 0\n",
    "total_f1 = 0\n",
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True)\n",
    "i = 0\n",
    "for train_idx, test_idx in skf.split(data_reformated, labels):\n",
    "    i+=1\n",
    "    X_train, X_test = data_reformated[train_idx], data_reformated[test_idx]\n",
    "    y_train, y_test = labels[train_idx], labels[test_idx]\n",
    "    D_train = xgb.DMatrix(X_train, label=y_train)\n",
    "    D_test = xgb.DMatrix(X_test, label=y_test)\n",
    "    param = {\n",
    "    'objective': 'multi:softprob',  \n",
    "    'num_class': len(set(labels))} \n",
    "\n",
    "    steps = 100  # The number of training iterations\n",
    "    model = xgb.train(param, D_train, steps)\n",
    "    preds = model.predict(D_test)\n",
    "    y_pred = np.asarray([np.argmax(line) for line in preds])\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    print(\"Fold accuracy: {:2.2f}\".format(acc))\n",
    "    print(\"Fold f1: {:2.2f}\".format(f1))\n",
    "    matrix = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Fold confusion matrix: \\n {}\".format(matrix))\n",
    "    total_acc += acc/n_splits\n",
    "    total_f1 += f1/n_splits\n",
    "\n",
    "print(\"Total model accuracy: {:2.2f}\".format(total_acc))\n",
    "print(\"Total model f1: {:2.2f}\".format(total_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, make_scorer\n",
    "\n",
    "f1 = make_scorer(f1_score , average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "clf = xgb.XGBClassifier()\n",
    "parameters = {\n",
    "     \"eta\"    : [0.05, 0.10, 0.15, 0.20, 0.25, 0.30 ] ,\n",
    "     \"max_depth\"        : [ 3, 4, 5, 6, 8, 10, 12, 15],\n",
    "     \"min_child_weight\" : [ 1, 3, 5, 7 ],\n",
    "     \"gamma\"            : [ 0.0, 0.1, 0.2 , 0.3, 0.4 ],\n",
    "     \"colsample_bytree\" : [ 0.3, 0.4, 0.5 , 0.7 ]\n",
    "     }\n",
    "\n",
    "grid = GridSearchCV(clf,\n",
    "                    parameters, n_jobs=4,\n",
    "                    scoring=f1,\n",
    "                    cv=3)\n",
    "\n",
    "grid.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_acc = 0\n",
    "total_f1 = 0\n",
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True)\n",
    "i = 0\n",
    "for train_idx, test_idx in skf.split(data[0], labels):\n",
    "    i+=1\n",
    "    x_train, y_train = [d[train_idx] for d in data], labels[train_idx]\n",
    "    x_test, y_test = [d[test_idx] for d in data], labels[test_idx]\n",
    "\n",
    "    y_train_cat = to_categorical(y_train)\n",
    "    y_test_cat = to_categorical(y_test)\n",
    "\n",
    "    cnns = []\n",
    "    for _ in range(adjs):\n",
    "        input_a = Input((*input_shape, 1))\n",
    "        x = Conv2D(8, 3)(input_a)\n",
    "        x = MaxPool2D(2)(x)\n",
    "        x = Flatten()(x)\n",
    "        x = Model(inputs=[input_a], outputs=x)\n",
    "        cnns.append(x)\n",
    "\n",
    "    combine = Concatenate()([x.output for x in cnns])\n",
    "    z = Dense(classes, activation='softmax')(combine)\n",
    "\n",
    "    model = Model(inputs=[x.input for x in cnns], outputs=z)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy', f1_metric])\n",
    "    model.fit(x_train, y_train_cat, batch_size=32, epochs=25, shuffle=True, validation_split=0.5)\n",
    "    y_pred = model.predict(x_test).argmax(axis=-1)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    print(\"Fold accuracy: {:2.2f}\".format(acc))\n",
    "    print(\"Fold f1: {:2.2f}\".format(f1))\n",
    "    matrix = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Fold confusion matrix: \\n {}\".format(matrix))\n",
    "    total_acc += acc/n_splits\n",
    "    total_f1 += f1/n_splits\n",
    "\n",
    "print(\"Total model accuracy: {:2.2f}\".format(total_acc))\n",
    "print(\"Total model f1: {:2.2f}\".format(total_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
